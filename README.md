
# Improving generalization via style transfer-based data augmentation: Novel regularization method

![Generated skin lesions: example.](https://raw.githubusercontent.com/AgaMiko/ST-DA/master/Skin-lesions-examples.jpg?token=AEYY5YZ6GN4RLZ26QVGEQHC5KFI2K)

## Introduction
Currently, deep learning (DL) algorithms are considered as state-of-the-art in many classification tasks,
and yet the problem of weak generalization is very common, widely mentioned, and still up-to-date.
One of the main goals in machine learning is to achieve the highest generalization ability of the trained model.
Although huge, multi-layered models are able to extract advanced features from great amounts of data,
unfortunately they often show a tendency to overfit.
The present paper focuses most on the data augmentation. In our method, new images are synthetized with neural style transfer (NST),
and the generated images are then used to train the convolutional neural network (CNN) in order to improve
its generalization abilities.  
The main contributions of this paper are:
*	The proposition of using neural style transfer for the data augmentation technique (ST-DA). This approach is presented on the skin lesion case study by transforming a benign skin lesion to a malignant lesion, and tested with dataset enrichment evaluation; 
*	Incorporating unlabeled, synthesized data into training by adding pseudo-labels generated by another CNN; 
*	Limiting the problem of noisy pseudo-labels in synthetic images used as a CNN training set by using only real images in validation and test sets;
*	Evaluating the ability to enrich the training dataset with artificially generated data with Deep Taylor Decomposition, 
* Proving that the ST-DA method significantly improves the performance and repeatability of training for deep neural networks.


## ST-DA
xxxx

## Database
### Database
The original dataset consisted of 1088 malignant skin lesions and 12433 benign images. Taking full advantage of the neural style transfer approach, 248 489 synthesized images were generated. In particular, only 418 malignant lesions were used from the original dataset to create the database.  Then, with the use of these data the performance of four types of popular and commonly used deep neural network architectures was evaluated. The networks were trained on 54030 synthesized images, validated on 1976 real images, and tested on 200 images per each of five testing folds (k-fold cross-validation).  
The following regularization techniques were applied to each tested network: traditional data augmentation (rotation, zoom, shear, reflection), dropout, and early stopping. In order to make comparison reliable, all the experiments were performed with the same hyperparameters, regularization techniques, and architectures. To evaluate the proposed approach, it was compared with other networks in terms of performance, repeatability, and the amount of new information carried in the generated dataset. 

### Source of original skin lesions
The used database was the publicly available dataset of Dermatoscopic images of the most common classes of skin lesions from The International Skin Imaging Collaboration: Melanoma Project Archive (Codella et al., 2018; Tschandl, Rosendahl, & Kittler, 2018). 

### Style transfer
The neural style transfer used in this work is based on [xx], with improvements detailed in [xx], and implemented in Keras 2.0. Going into the details, the VGG16 Convolutional Neural Network was used with the input image of 224x224 px and Conv5_2 as the content layer (detailed notation in [xxx]). Each image was initialized by the content picture, the content weight equal to 0.025, the style weight equal to 1.0, and the pooling layer with pool size defined by the maximum operator. 

### Architecture and training
For pseudo-labelling, VGG16 trained on a skin lesion dataset was used (full description in [xxx]).
Moreover, VGG8 and VGG11 implementations as described in (Grochowski, Kwasigroch, & Mikolajczyk, 2019) were used, along with VGG16 and DenseNet121 from Keras 2.0 [xxx]. The following regularization techniques were applied to each tested network: traditional data augmentation (rotation, zoom, shear, reflection), dropout, and early stopping. All the experiments were performed with the same hyperparameters, regularization techniques, and architectures, in order to make comparison reliable.


### If you use this database please star the repository and cite the following paper:

**xxxx
